{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25e990e8",
   "metadata": {},
   "source": [
    "## Testing assemble circuitry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f357aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Repo root: c:\\Users\\Bahrs\\Documents\\_GitHub\\gas-sensor_SWCNT_film-data-classification\n",
      "âœ“ Python can now import from 'src/'\n"
     ]
    }
   ],
   "source": [
    "# # ===== SETUP CELL - Run this first =====\n",
    "# import sys\n",
    "# from pathlib import Path\n",
    "\n",
    "# # Get repo root (assuming notebook is in notebooks/ folder)\n",
    "# repo_root = Path.cwd().parents[0] if 'notebooks' in str(Path.cwd()) else Path.cwd()\n",
    "\n",
    "# # Add to Python path\n",
    "# if str(repo_root) not in sys.path:\n",
    "#     sys.path.insert(0, str(repo_root))\n",
    "\n",
    "# print(f\"âœ“ Repo root: {repo_root}\")\n",
    "# print(f\"âœ“ Python can now import from 'src/'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1db355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(481998, 6) (1199, 408) (1199, 408) (3543, 408)\n",
      "['V', 'I', 'MFC_target', 'flow_target_error', 'flow_carrier_error', 'meas_cycle']\n",
      "['NO2', 'H2S', 'Acet', 'meas_cycle', 'gas_', 'class_']\n",
      "['NO2', 'H2S', 'Acet', 'meas_cycle', 'gas_', 'class_']\n",
      "['NO2', 'H2S', 'Acet', 'meas_cycle', 'gas_', 'class_']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from thermocycling.pipeline.loading import load_gas_data  # pyright: ignore[reportMissingImports]\n",
    "from thermocycling.pipeline.assemble import build_basic_dataset, full_dataset\n",
    "from thermocycling.pipeline.cleaning import apply_manual_trim  # pyright: ignore[reportMissingImports]\n",
    "from thermocycling.preprocessing.smoothing import dedrift, Exp_pd\n",
    "#from data.paths import GAS_FILE_MAP\n",
    "\n",
    "gas = 'NO2'\n",
    "df = load_gas_data(gas)\n",
    "df1 = build_basic_dataset(gas)\n",
    "df2 = dedrift(df1, 201, Exp_pd, alpha = 0.0217)\n",
    "df3 = full_dataset(Exp_pd, envelope_ind = [201], alpha = 0.0217)\n",
    "print(df.shape, df1.shape, df2.shape, df3.shape)\n",
    "print(df.columns[-6:].tolist(), df1.columns[-6:].tolist(), df2.columns[-6:].tolist(), df3.columns[-6:].tolist(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cde7a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thermocycling.preprocessing.train_test import build_sequences_for_df\n",
    "#df3[df3[\"gas_\"] == 'NO2'].loc[:,['NO2', 'H2S', 'Acet']]\n",
    "data = build_sequences_for_df(df3, look_back=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0219ecd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CATBOOST FOLDS (2D)\n",
      "============================================================\n",
      "TimeSeriesCVSplitter: 4 folds\n",
      "\n",
      "  Fold 0: train=2145, test=360, features=(50,)\n",
      "  Fold 1: train=2505, test=360, features=(50,)\n",
      "  Fold 2: train=2865, test=360, features=(50,)\n",
      "  Fold 3: train=3225, test=318, features=(50,)\n"
     ]
    }
   ],
   "source": [
    "from thermocycling.preprocessing.train_test import create_time_series_folds\n",
    "print(\"=\" * 60)\n",
    "print(\"CATBOOST FOLDS (2D)\")\n",
    "print(\"=\" * 60)\n",
    "cb_folds = create_time_series_folds(\n",
    "    df3,\n",
    "    model_type='catboost',\n",
    "    feature_cols=402,\n",
    "    target_cols=['NO2', 'H2S', 'Acet'],\n",
    "    n_components=50,\n",
    "    start_cycle=5\n",
    ")\n",
    "\n",
    "print(cb_folds.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d435bf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "LSTM FOLDS (3D)\n",
      "============================================================\n",
      "TimeSeriesCVSplitter: 3 folds\n",
      "\n",
      "  Fold 0: train=1698, test=273, features=(150, 50)\n",
      "  Fold 1: train=2058, test=273, features=(150, 50)\n",
      "  Fold 2: train=2418, test=231, features=(150, 50)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LSTM FOLDS (3D)\")\n",
    "print(\"=\" * 60)\n",
    "lstm_folds = create_time_series_folds(\n",
    "    df3,\n",
    "    model_type='lstm',\n",
    "    feature_cols=402,\n",
    "    target_cols=['NO2', 'H2S', 'Acet'],\n",
    "    look_back=150,\n",
    "    n_components=50,\n",
    "    start_cycle=5,\n",
    "    test_size=2,\n",
    ")\n",
    "print(lstm_folds.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d61b496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TENSORFLOW DATASETS\n",
      "============================================================\n",
      "First fold - Train dataset: <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 150, 50), dtype=tf.float64, name=None), TensorSpec(shape=(None, 3), dtype=tf.float64, name=None))>\n",
      "First fold - Test dataset: <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 150, 50), dtype=tf.float64, name=None), TensorSpec(shape=(None, 3), dtype=tf.float64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "# Test TensorFlow dataset conversion\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TENSORFLOW DATASETS\")\n",
    "print(\"=\" * 60)\n",
    "tf_datasets = lstm_folds.to_tf_datasets(batch_size=32)\n",
    "train_ds, test_ds = tf_datasets[0]\n",
    "print(f\"First fold - Train dataset: {train_ds}\")\n",
    "print(f\"First fold - Test dataset: {test_ds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05affde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SAVE/LOAD TEST\n",
      "============================================================\n",
      "Successfully saved and loaded 4 folds\n"
     ]
    }
   ],
   "source": [
    "from thermocycling.preprocessing.train_test import TimeSeriesCVSplitter\n",
    "# Test save/load\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAVE/LOAD TEST\")\n",
    "print(\"=\" * 60)\n",
    "cb_folds.save('test_folds')\n",
    "loaded_folds = TimeSeriesCVSplitter.load('test_folds')\n",
    "print(f\"Successfully saved and loaded {len(loaded_folds)} folds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aae25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_imports():\n",
    "    \"\"\"Test that all modules can be imported.\"\"\"\n",
    "    print(\"Testing imports...\")\n",
    "    \n",
    "    try:\n",
    "        from thermocycling.pipeline.loading import load_gas_data\n",
    "        from thermocycling.pipeline.cleaning import apply_manual_trim\n",
    "        from thermocycling.pipeline.assemble import build_basic_dataset, full_dataset\n",
    "        from thermocycling.preprocessing.smoothing import Exp_pd, Savitzky_Golay, dedrift\n",
    "        from thermocycling.preprocessing.train_test import create_time_series_folds\n",
    "        from thermocycling.models.catboost_model import build_catboost_classifier, build_catboost_regressor\n",
    "        from thermocycling.models.lstm_model import build_lstm\n",
    "        from thermocycling.models.optuna_objectives import (\n",
    "            LSTMRegressorObjective,\n",
    "            CatBoostClassifierObjective\n",
    "        )\n",
    "        print(\"âœ“ All imports successful\")\n",
    "        return True\n",
    "    except ImportError as e:\n",
    "        print(f\"âœ— Import failed: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def test_data_loading():\n",
    "    \"\"\"Test data loading pipeline.\"\"\"\n",
    "    print(\"\\nTesting data loading...\")\n",
    "    \n",
    "    try:\n",
    "        from thermocycling.pipeline.assemble import full_dataset\n",
    "        from thermocycling.preprocessing.smoothing import Exp_pd\n",
    "        \n",
    "        df = full_dataset(\n",
    "            dedrifting_func=Exp_pd,\n",
    "            envelope_ind=[201],\n",
    "            alpha=0.0217\n",
    "        )\n",
    "        \n",
    "        assert df.shape[1] == 408, f\"Expected 408 columns, got {df.shape[1]}\"\n",
    "        assert 'NO2' in df.columns, \"Missing NO2 column\"\n",
    "        assert 'class_' in df.columns, \"Missing class_ column\"\n",
    "        assert 'meas_cycle' in df.columns, \"Missing meas_cycle column\"\n",
    "        \n",
    "        print(f\"âœ“ Data loaded successfully: {df.shape}\")\n",
    "        print(f\"  Gases: {df['gas_'].unique()}\")\n",
    "        print(f\"  Cycles: {df['meas_cycle'].min()} - {df['meas_cycle'].max()}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Data loading failed: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def test_cv_splitting():\n",
    "    \"\"\"Test CV splitting for both model types.\"\"\"\n",
    "    print(\"\\nTesting CV splitting...\")\n",
    "    \n",
    "    try:\n",
    "        from thermocycling.pipeline.assemble import full_dataset\n",
    "        from thermocycling.preprocessing.smoothing import Exp_pd\n",
    "        from thermocycling.preprocessing.train_test import create_time_series_folds\n",
    "        \n",
    "        df = full_dataset(\n",
    "            dedrifting_func=Exp_pd,\n",
    "            envelope_ind=[201],\n",
    "            alpha=0.0217\n",
    "        )\n",
    "        \n",
    "        # Test CatBoost folds\n",
    "        catboost_folds = create_time_series_folds(\n",
    "            df,\n",
    "            model_type='catboost',\n",
    "            task_type='regressor',\n",
    "            n_components=50,\n",
    "            start_cycle=7,\n",
    "            test_size=1\n",
    "        )\n",
    "        print(f\"âœ“ CatBoost folds: {len(catboost_folds)} folds\")\n",
    "        \n",
    "        # Test LSTM folds\n",
    "        lstm_folds = create_time_series_folds(\n",
    "            df,\n",
    "            model_type='lstm',\n",
    "            task_type='regressor',\n",
    "            look_back=30,\n",
    "            n_components=50,\n",
    "            start_cycle=7,\n",
    "            test_size=1\n",
    "        )\n",
    "        print(f\"âœ“ LSTM folds: {len(lstm_folds)} folds\")\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— CV splitting failed: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def test_model_building():\n",
    "    \"\"\"Test model building.\"\"\"\n",
    "    print(\"\\nTesting model building...\")\n",
    "    \n",
    "    try:\n",
    "        from thermocycling.models.catboost_model import build_catboost_regressor\n",
    "        from thermocycling.models.lstm_model import build_lstm\n",
    "        \n",
    "        # Test CatBoost\n",
    "        catboost_model = build_catboost_regressor(iterations=10, verbose=False)\n",
    "        print(\"âœ“ CatBoost model built\")\n",
    "        \n",
    "        # Test LSTM\n",
    "        lstm_model = build_lstm(\n",
    "            input_shape=(30, 50),  # (look_back, n_features)\n",
    "            output_shape=3,  # 3 gas concentrations\n",
    "            n_layers=2,\n",
    "            n_units=32\n",
    "        )\n",
    "        lstm_model.build(input_shape=(None, 30, 50))  # Build the model first\n",
    "        print(\"âœ“ LSTM model built\")\n",
    "        print(f\"  LSTM parameters: {lstm_model.count_params():,}\")\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Model building failed: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def test_config_loading():\n",
    "    \"\"\"Test config file loading.\"\"\"\n",
    "    print(\"\\nTesting config loading...\")\n",
    "    \n",
    "    try:\n",
    "        import yaml\n",
    "        \n",
    "        config_files = [\n",
    "            'configs/config_lstm_regression.yaml',\n",
    "            'configs/config_catboost_classification.yaml',\n",
    "            'configs/config_catboost_regression.yaml'\n",
    "        ]\n",
    "        \n",
    "        for config_file in config_files:\n",
    "            config_path = PROJECT_ROOT / config_file\n",
    "            if not config_path.exists():\n",
    "                print(f\"âš  Config file not found: {config_file}\")\n",
    "                continue\n",
    "                \n",
    "            with open(config_path, 'r') as f:\n",
    "                config = yaml.safe_load(f)\n",
    "            \n",
    "            assert 'experiment' in config, f\"Missing 'experiment' in {config_file}\"\n",
    "            assert 'data' in config, f\"Missing 'data' in {config_file}\"\n",
    "            print(f\"âœ“ Config loaded: {config_file}\")\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Config loading failed: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c7b3dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TESTING SETUP\n",
      "============================================================\n",
      "Testing imports...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bahrs\\Documents\\_GitHub\\gas-sensor_SWCNT_film-data-classification\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ All imports successful\n",
      "\n",
      "Testing data loading...\n",
      "âœ“ Data loaded successfully: (3543, 408)\n",
      "  Gases: ['NO2' 'H2S' 'Acet']\n",
      "  Cycles: 0 - 9\n",
      "\n",
      "Testing CV splitting...\n",
      "âœ“ CatBoost folds: 2 folds\n",
      "âœ“ LSTM folds: 2 folds\n",
      "\n",
      "Testing model building...\n",
      "âœ“ CatBoost model built\n",
      "âœ“ LSTM model built\n",
      "  LSTM parameters: 13,811\n",
      "\n",
      "Testing config loading...\n",
      "âœ“ Config loaded: configs/config_lstm_regression.yaml\n",
      "âœ“ Config loaded: configs/config_catboost_classification.yaml\n",
      "âœ“ Config loaded: configs/config_catboost_regression.yaml\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "âœ“ PASS: Imports\n",
      "âœ“ PASS: Data Loading\n",
      "âœ“ PASS: CV Splitting\n",
      "âœ“ PASS: Model Building\n",
      "âœ“ PASS: Config Loading\n",
      "\n",
      "ðŸŽ‰ All tests passed! Your setup is ready.\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"TESTING SETUP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "tests = [\n",
    "    (\"Imports\", test_imports),\n",
    "    (\"Data Loading\", test_data_loading),\n",
    "    (\"CV Splitting\", test_cv_splitting),\n",
    "    (\"Model Building\", test_model_building),\n",
    "    (\"Config Loading\", test_config_loading),\n",
    "]\n",
    "\n",
    "results = []\n",
    "for name, test_func in tests:\n",
    "    try:\n",
    "        success = test_func()\n",
    "        results.append((name, success))\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Test '{name}' crashed: {e}\")\n",
    "        results.append((name, False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for name, success in results:\n",
    "    status = \"âœ“ PASS\" if success else \"âœ— FAIL\"\n",
    "    print(f\"{status}: {name}\")\n",
    "\n",
    "all_passed = all(success for _, success in results)\n",
    "\n",
    "if all_passed:\n",
    "    print(\"\\nðŸŽ‰ All tests passed! Your setup is ready.\")\n",
    "else:\n",
    "    print(\"\\nâŒ Some tests failed. Check the errors above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335e48bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import yaml\n",
    "import argparse\n",
    "import mlflow\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "#PROJECT_ROOT = Path(__file__).resolve().parents[1]  # PROJECT_ROOT = Path(__file__).resolve().parents[0]\n",
    "#sys.path.insert(0, str(PROJECT_ROOT / \"src\"))\n",
    "\n",
    "from thermocycling.pipeline.assemble import full_dataset\n",
    "from thermocycling.preprocessing.smoothing import Exp_pd, Savitzky_Golay\n",
    "from thermocycling.models.optuna_objectives import (\n",
    "    run_lstm_regressor_optimization,\n",
    "    run_lstm_classifier_optimization,\n",
    "    run_catboost_classifier_optimization,\n",
    "    run_catboost_regressor_optimization\n",
    ")\n",
    "\n",
    "\n",
    "DEDRIFT_METHODS = {\n",
    "    'Exp_pd': Exp_pd,\n",
    "    'Savitzky_Golay': Savitzky_Golay\n",
    "}\n",
    "\n",
    "\n",
    "def load_config(config_path: str) -> dict:\n",
    "    \"\"\"Load YAML configuration file.\"\"\"\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    return config\n",
    "\n",
    "\n",
    "def prepare_data(config: dict):\n",
    "    \"\"\"Prepare dataset according to config.\"\"\"\n",
    "    data_cfg = config['data']\n",
    "    \n",
    "    # Get dedrift method\n",
    "    dedrift_method_name = data_cfg['dedrift_method']\n",
    "    dedrift_func = DEDRIFT_METHODS[dedrift_method_name]\n",
    "    dedrift_params = data_cfg['dedrift_params']\n",
    "    \n",
    "    # Load full dataset\n",
    "    df = full_dataset(\n",
    "        dedrifting_func=dedrift_func,\n",
    "        **dedrift_params\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ“ Loaded dataset: {df.shape}\")\n",
    "    print(f\"  Gases: {df['gas_'].unique()}\")\n",
    "    print(f\"  Measurement cycles: {df['meas_cycle'].min()} - {df['meas_cycle'].max()}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def run_optimization(config: dict, df):\n",
    "    \"\"\"Run optimization based on config.\"\"\"\n",
    "    exp_cfg = config['experiment']\n",
    "    opt_cfg = config['optimization']\n",
    "    mlflow_cfg = config['mlflow']\n",
    "    preproc_cfg = config['preprocessing']\n",
    "    \n",
    "    # Set MLflow tracking URI\n",
    "    mlflow.set_tracking_uri(mlflow_cfg['tracking_uri'])\n",
    "    \n",
    "    # Prepare objective kwargs\n",
    "    objective_kwargs = {\n",
    "        'cv_start_cycle': preproc_cfg['cv_start_cycle'],\n",
    "        'cv_test_size': preproc_cfg['cv_test_size'],\n",
    "        'feature_cols': config['data']['feature_cols']\n",
    "    }\n",
    "    \n",
    "    # Add model-specific parameters\n",
    "    if exp_cfg['model_type'] == 'lstm':\n",
    "        objective_kwargs.update({\n",
    "            'look_back_range': preproc_cfg['look_back_range'],\n",
    "            'n_components_range': preproc_cfg['n_components_range']\n",
    "        })\n",
    "        \n",
    "        if exp_cfg['task'] == 'regression':\n",
    "            objective_kwargs['target_cols'] = config['data']['target_cols']\n",
    "    \n",
    "    elif exp_cfg['model_type'] == 'catboost':\n",
    "        objective_kwargs['n_components_range'] = preproc_cfg['n_components_range']\n",
    "        \n",
    "        if exp_cfg['task'] == 'regression':\n",
    "            objective_kwargs['target_cols'] = config['data']['target_cols']\n",
    "    \n",
    "    # Select optimization function\n",
    "    if exp_cfg['model_type'] == 'lstm' and exp_cfg['task'] == 'regression':\n",
    "        optimize_func = run_lstm_regressor_optimization\n",
    "    elif exp_cfg['model_type'] == 'lstm' and exp_cfg['task'] == 'classification':\n",
    "        optimize_func = run_lstm_classifier_optimization\n",
    "    elif exp_cfg['model_type'] == 'catboost' and exp_cfg['task'] == 'classification':\n",
    "        optimize_func = run_catboost_classifier_optimization\n",
    "    elif exp_cfg['model_type'] == 'catboost' and exp_cfg['task'] == 'regression':\n",
    "        optimize_func = run_catboost_regressor_optimization\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Unknown model_type/task combination: \"\n",
    "            f\"{exp_cfg['model_type']}/{exp_cfg['task']}\")\n",
    "    \n",
    "    # Run optimization\n",
    "    print(f\"\\nðŸš€ Starting optimization: {exp_cfg['name']}\")\n",
    "    print(f\"   Study: {exp_cfg['study_name']}\")\n",
    "    print(f\"   Trials: {opt_cfg['n_trials']}\")\n",
    "    print(f\"   Direction: {opt_cfg['direction']}\")\n",
    "    \n",
    "    study = optimize_func(\n",
    "        df,\n",
    "        study_name=exp_cfg['study_name'],\n",
    "        mlflow_experiment_name=exp_cfg['name'],\n",
    "        n_trials=opt_cfg['n_trials'],\n",
    "        timeout=opt_cfg['timeout'],\n",
    "        direction=opt_cfg['direction'],\n",
    "        objective_kwargs=objective_kwargs\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nâœ“ Optimization complete!\")\n",
    "    print(f\"  Best value: {study.best_value:.6f}\")\n",
    "    print(f\"  Best params: {study.best_params}\")\n",
    "    \n",
    "    return study\n",
    "\n",
    "\n",
    "def optimization_from_config_main():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Run hyperparameter optimization from config file\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        'config',\n",
    "        type=str,\n",
    "        help='Path to YAML config file'\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Load config\n",
    "    print(f\"ðŸ“„ Loading config: {args.config}\")\n",
    "    config = load_config(args.config)\n",
    "    \n",
    "    # Prepare data\n",
    "    print(f\"\\nðŸ“Š Preparing data...\")\n",
    "    df = prepare_data(config)\n",
    "    \n",
    "    # Run optimization\n",
    "    study = run_optimization(config, df)\n",
    "    \n",
    "    print(f\"\\nâœ… Done! MLflow experiment: {config['experiment']['name']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
